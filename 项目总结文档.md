# 🍎 食品AI科研问答系统 - 完整项目文档

## 📋 项目概述

基于 LlamaIndex + DeepSeek-R1 的智能科研问答系统，专为食品科学研究设计。系统采用RAG（检索增强生成）架构，结合本地中文嵌入模型和云端推理模型，提供智能的文献问答服务。

## ✨ 核心特性

- 🤖 **智能问答**：基于DeepSeek-R1推理模型，深度理解科研问题
- 📚 **文献检索**：自动从上传的文献中检索相关内容
- 🇨🇳 **中文优化**：使用本地中文嵌入模型BAAI/bge-small-zh-v1.5，完全免费
- 💾 **持久化存储**：索引自动保存，重启秒级加载
- 📤 **Web上传**：支持Web界面上传PDF、Word等文档
- 🔒 **隐私保护**：文档本地处理，数据不上传云端

## 🚀 快速开始

### 1. 环境准备
```bash
# 克隆项目
git clone https://github.com/YOUR_USERNAME/food-ai-research-qa.git
cd food-ai-research-qa

# 安装依赖
pip install -r requirements.txt

# 配置环境变量
cp .env.example .env
# 编辑.env文件，填入DeepSeek API密钥
```

### 2. 启动系统
```bash
python app.py
# 访问 http://localhost:5001/
```

### 3. 使用方式
1. 通过Web界面上传文献（支持PDF、Word、TXT等格式）
2. 在问答界面输入问题
3. 获得AI回答和参考文献

## 📁 项目结构

### 核心文件
```
app.py                          # Flask主应用
persistent_storage.py           # 持久化存储管理
upload_handler.py               # 文件上传处理
```

### 前端文件
```
frontend/                       # HTML模板
├── index.html                 # 主页
├── search.html                # 搜索页
├── management.html            # 管理页
├── upload.html                # 上传页
└── about.html                 # 关于页

static/                        # 静态资源
├── style.css                  # 样式文件
├── main.js                    # 主页脚本
├── search.js                  # 搜索脚本
├── management.js              # 管理脚本
└── upload.js                  # 上传脚本
```

### 配置文件
```
.env                           # 环境变量（不提交）
.env.example                   # 环境变量模板
.gitignore                     # Git忽略文件
requirements.txt               # Python依赖
pyproject.toml                 # 项目配置
```

### 数据目录
```
food_research_data/            # 文献数据
├── papers/                    # 论文
└── datasets/                  # 数据集

storage/                       # 向量索引（自动生成）
models/                        # 嵌入模型（自动下载）
rag_outputs/                   # RAG输出结果
```

### 脚本和工具
```
启动Flask应用.sh               # 启动脚本
部署到Git.sh                   # Git部署脚本
test_pdf_upload.py             # 测试脚本
notebooks/                     # 示例和教程脚本
```

## 🧠 技术架构

### 系统架构
```
用户问题 → 向量化 → 检索文档 → DeepSeek-R1推理 → 答案
```

### 技术栈
- **LLM**: DeepSeek-R1 推理模型
- **嵌入**: BAAI/bge-small-zh-v1.5 (本地中文)
- **框架**: LlamaIndex RAG
- **前端**: Flask + HTML/CSS/JS
- **存储**: 本地持久化存储

### 嵌入模型详解

**什么是嵌入模型？**
嵌入模型将文本转换为数字向量，捕捉文本的语义信息。在RAG系统中：
1. **文档索引阶段**：将所有文档转换为向量存储
2. **查询阶段**：将用户问题转换为查询向量
3. **检索阶段**：通过向量相似度找到最相关的文档

**推荐模型：BAAI/bge-small-zh-v1.5**
- 模型大小：约400MB
- 向量维度：512维
- 中文优化：专门针对中文训练
- 完全免费，本地运行

## 📚 数据库和存储

### 持久化存储（默认方案）
- ✅ 自动保存索引到 `./storage` 目录
- ✅ 重启后自动加载，无需重建
- ✅ 只在上传新文档时才重建
- ✅ 完全免费，无需外部服务

### 外部数据库选项
1. **Chroma**（推荐升级方案）
   - 完全免费，本地运行
   - 支持增量更新
   - 性能优秀

2. **Qdrant**（生产环境推荐）
   - 高性能，支持大规模数据
   - 可本地或云端部署
   - 有免费云服务额度

3. **Pinecone**（云端托管）
   - 完全托管，无需维护
   - 自动扩展，高可用性
   - 有免费额度

## 📤 文档上传方式

### 方式1: Web界面上传（推荐）
1. 访问 `http://localhost:5001/upload.html`
2. 选择文件类型（论文/数据集）
3. 选择文件并上传
4. 系统自动向量化

### 方式2: 直接复制文件
```bash
# 将文件放入目录
cp your_paper.pdf food_research_data/papers/
# 重启系统（自动向量化）
python app.py
```

### 方式3: API上传
```python
import requests
files = {'files': open('paper.pdf', 'rb')}
data = {'category': 'papers'}
response = requests.post('http://localhost:5001/api/upload', files=files, data=data)
```

### 支持格式
- ✅ PDF (.pdf)
- ✅ Word (.doc, .docx)
- ✅ 文本 (.txt, .md)
- ✅ CSV (.csv)
- ✅ JSON (.json)

## 🛠️ 系统要求

- Python 3.8+
- 2GB+ 内存
- 500MB+ 磁盘空间（用于模型缓存）
- 网络连接（首次下载模型和调用API）

## 💰 成本说明

- **嵌入模型**：完全免费（本地运行）
- **DeepSeek API**：约 ¥0.014/千tokens（非常便宜）
- **向量存储**：免费（本地存储）

## 📊 性能对比

| 模型 | 大小 | 维度 | 中文效果 | 速度 | 成本 |
|------|------|------|----------|------|------|
| OpenAI ada-002 | API | 1536 | ⭐⭐⭐⭐ | 快 | 付费 |
| bge-small-zh | 400MB | 512 | ⭐⭐⭐⭐⭐ | 快 | 免费 |
| bge-large-zh | 1.3GB | 1024 | ⭐⭐⭐⭐⭐ | 中 | 免费 |

## 🔧 故障排查

### 常见问题
1. **索引加载失败**：删除 `storage/` 目录，重新构建
2. **内存不足**：使用外部数据库或减少chunk_size
3. **查询速度慢**：减少检索数量（similarity_top_k）
4. **首次下载慢**：使用国内镜像 `HF_ENDPOINT=https://hf-mirror.com`

## 💡 最佳实践

### 开发阶段
- 使用默认的本地持久化存储
- 使用 bge-small-zh 嵌入模型（快速、够用）

### 生产环境
- 小规模：使用 Chroma 数据库
- 大规模：使用 Qdrant 云服务
- 企业级：使用 Pinecone 或自建 Qdrant 集群

### 配置优化
```python
# 环境变量配置
DEEPSEEK_API_KEY=your_api_key
DEEPSEEK_MODEL=deepseek-reasoner

# 性能调优
Settings.chunk_size = 512  # 文档分块大小
similarity_top_k = 5       # 检索文档数量
```

## 📖 示例脚本

```bash
# 完整RAG系统演示
python notebooks/04_DeepSeek完整版.py

# 向量化演示
python notebooks/06_文献向量化演示.py

# 外部数据库集成
python notebooks/08_外部数据库集成.py
```

## 🤝 贡献指南

欢迎提交Issue和Pull Request！项目采用MIT许可证。

## 🙏 致谢

- [LlamaIndex](https://www.llamaindex.ai/) - RAG框架
- [DeepSeek](https://www.deepseek.com/) - LLM服务
- [BAAI](https://www.baai.ac.cn/) - 中文嵌入模型

## 📧 联系方式

如有问题，请提交Issue或联系维护者。

---

⭐ **开始你的食品AI科研之旅！**

访问：http://localhost:5001

**推荐配置：DeepSeek API (LLM) + bge-small-zh-v1.5 (嵌入)**
- DeepSeek便宜且中文能力强
- 本地嵌入模型免费且隐私安全
- 组合使用性价比最高

---

*本文档整合了项目的所有核心信息，包括架构设计、使用指南、技术详解和最佳实践。*