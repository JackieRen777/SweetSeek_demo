#!/usr/bin/env python3
"""
æµ‹è¯•PDFä¸Šä¼ å’Œå‘é‡åŒ–
æ¼”ç¤ºå¦‚ä½•å¤„ç†ä¸åŒæ ¼å¼çš„æ–‡çŒ®
"""

import os
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

def test_document_reading():
    """æµ‹è¯•æ–‡æ¡£è¯»å–"""
    print("=" * 60)
    print("ğŸ“„ æµ‹è¯•æ–‡æ¡£è¯»å–åŠŸèƒ½")
    print("=" * 60)
    
    # é…ç½®åµŒå…¥æ¨¡å‹
    Settings.embed_model = HuggingFaceEmbedding(
        model_name="BAAI/bge-small-zh-v1.5",
        cache_folder="./models"
    )
    
    # è¯»å–æ‰€æœ‰æ–‡æ¡£
    print("\n[1] è¯»å– food_research_data ç›®å½•...")
    try:
        documents = SimpleDirectoryReader(
            "food_research_data",
            recursive=True
        ).load_data()
        
        print(f"âœ… æˆåŠŸè¯»å– {len(documents)} ä¸ªæ–‡æ¡£\n")
        
        # æ˜¾ç¤ºæ¯ä¸ªæ–‡æ¡£çš„è¯¦ç»†ä¿¡æ¯
        for i, doc in enumerate(documents, 1):
            filename = doc.metadata.get('file_name', 'æœªçŸ¥æ–‡ä»¶')
            file_path = doc.metadata.get('file_path', '')
            file_type = os.path.splitext(filename)[1]
            content_length = len(doc.text)
            
            print(f"æ–‡æ¡£ {i}:")
            print(f"  ğŸ“ æ–‡ä»¶å: {filename}")
            print(f"  ğŸ“‚ è·¯å¾„: {file_path}")
            print(f"  ğŸ“ æ ¼å¼: {file_type}")
            print(f"  ğŸ“Š å†…å®¹é•¿åº¦: {content_length} å­—ç¬¦")
            print(f"  ğŸ“– å‰150å­—é¢„è§ˆ:")
            print(f"     {doc.text[:150].replace(chr(10), ' ')}...")
            print()
        
        return documents
        
    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥: {e}")
        return None

def test_vectorization(documents):
    """æµ‹è¯•å‘é‡åŒ–"""
    print("=" * 60)
    print("ğŸ”„ æµ‹è¯•å‘é‡åŒ–åŠŸèƒ½")
    print("=" * 60)
    
    if not documents:
        print("âŒ æ²¡æœ‰æ–‡æ¡£å¯ä»¥å‘é‡åŒ–")
        return None
    
    try:
        print("\n[2] å¼€å§‹å‘é‡åŒ–...")
        print("â³ è¿™å¯èƒ½éœ€è¦å‡ ç§’åˆ°å‡ åˆ†é’Ÿï¼Œå–å†³äºæ–‡æ¡£æ•°é‡...")
        
        # æ„å»ºå‘é‡ç´¢å¼•
        index = VectorStoreIndex.from_documents(documents)
        
        print("âœ… å‘é‡åŒ–å®Œæˆï¼")
        
        # è·å–å‘é‡å­˜å‚¨ä¿¡æ¯
        vector_store = index.storage_context.vector_store
        print(f"\nğŸ“Š å‘é‡æ•°æ®åº“ç»Ÿè®¡:")
        print(f"  - æ–‡æ¡£æ•°: {len(documents)}")
        print(f"  - å‘é‡ç»´åº¦: 512 (bge-small-zh-v1.5)")
        
        return index
        
    except Exception as e:
        print(f"âŒ å‘é‡åŒ–å¤±è´¥: {e}")
        return None

def test_query(index):
    """æµ‹è¯•æŸ¥è¯¢"""
    print("\n" + "=" * 60)
    print("ğŸ” æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½")
    print("=" * 60)
    
    if not index:
        print("âŒ ç´¢å¼•æœªåˆ›å»ºï¼Œæ— æ³•æŸ¥è¯¢")
        return
    
    # åˆ›å»ºæŸ¥è¯¢å¼•æ“
    query_engine = index.as_query_engine(
        similarity_top_k=3,
        response_mode="compact"
    )
    
    # æµ‹è¯•æŸ¥è¯¢
    test_questions = [
        "è¿™äº›æ–‡çŒ®ä¸»è¦ç ”ç©¶ä»€ä¹ˆå†…å®¹ï¼Ÿ",
        "æœ‰å…³äºé£Ÿå“å®‰å…¨çš„å†…å®¹å—ï¼Ÿ",
        "æŠ—æ°§åŒ–å‰‚æœ‰ä»€ä¹ˆä½œç”¨ï¼Ÿ"
    ]
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n[é—®é¢˜ {i}] {question}")
        print("-" * 60)
        
        try:
            # åªæ£€ç´¢ï¼Œä¸ç”Ÿæˆç­”æ¡ˆï¼ˆå› ä¸ºæ²¡æœ‰é…ç½®LLMï¼‰
            retriever = index.as_retriever(similarity_top_k=3)
            nodes = retriever.retrieve(question)
            
            print(f"âœ… æ‰¾åˆ° {len(nodes)} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ:\n")
            
            for j, node in enumerate(nodes, 1):
                score = node.score if hasattr(node, 'score') else 0.0
                filename = node.metadata.get('file_name', 'æœªçŸ¥')
                content = node.text[:200].replace('\n', ' ')
                
                print(f"  [{j}] ç›¸å…³åº¦: {score:.3f}")
                print(f"      æ¥æº: {filename}")
                print(f"      å†…å®¹: {content}...")
                print()
                
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")

def test_supported_formats():
    """æµ‹è¯•æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
    print("=" * 60)
    
    supported_formats = {
        "æ–‡æœ¬æ–‡ä»¶": [".txt", ".md", ".rst"],
        "æ–‡æ¡£æ–‡ä»¶": [".pdf", ".doc", ".docx"],
        "æ•°æ®æ–‡ä»¶": [".csv", ".json", ".jsonl"],
        "ä»£ç æ–‡ä»¶": [".py", ".js", ".java", ".cpp"],
        "ç½‘é¡µæ–‡ä»¶": [".html", ".htm"]
    }
    
    print("\nLlamaIndex è‡ªåŠ¨æ”¯æŒä»¥ä¸‹æ ¼å¼:\n")
    for category, formats in supported_formats.items():
        print(f"  {category}:")
        for fmt in formats:
            print(f"    âœ… {fmt}")
    
    print("\nğŸ’¡ æç¤º:")
    print("  - PDFæ–‡ä»¶ä¼šè‡ªåŠ¨æå–æ–‡æœ¬")
    print("  - Wordæ–‡ä»¶éœ€è¦å®‰è£…: pip install python-docx")
    print("  - æ‰«æç‰ˆPDFéœ€è¦OCR: pip install pytesseract")

def show_upload_instructions():
    """æ˜¾ç¤ºä¸Šä¼ è¯´æ˜"""
    print("\n" + "=" * 60)
    print("ğŸ“¤ å¦‚ä½•ä¸Šä¼ æ–°æ–‡çŒ®")
    print("=" * 60)
    
    print("""
æ–¹æ³•1: ç›´æ¥å¤åˆ¶æ–‡ä»¶
    cp your_paper.pdf food_research_data/papers/
    python app.py

æ–¹æ³•2: Webç•Œé¢ä¸Šä¼ 
    python app.py
    è®¿é—®: http://localhost:5001/upload.html
    
æ–¹æ³•3: æ‰¹é‡ä¸Šä¼ 
    cp *.pdf food_research_data/papers/
    python app.py

ğŸ“ ç›®å½•ç»“æ„:
    food_research_data/
    â”œâ”€â”€ papers/      â† ç ”ç©¶è®ºæ–‡æ”¾è¿™é‡Œ
    â””â”€â”€ datasets/    â† æ•°æ®é›†æ”¾è¿™é‡Œ
    """)

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸš€ " * 20)
    print("PDFä¸Šä¼ å’Œå‘é‡åŒ–æµ‹è¯•å·¥å…·")
    print("ğŸš€ " * 20 + "\n")
    
    # æ£€æŸ¥ç›®å½•
    if not os.path.exists("food_research_data"):
        print("âŒ æ‰¾ä¸åˆ° food_research_data ç›®å½•")
        print("ğŸ’¡ è¯·å…ˆåˆ›å»ºç›®å½•: mkdir -p food_research_data/papers food_research_data/datasets")
        return
    
    # æµ‹è¯•1: è¯»å–æ–‡æ¡£
    documents = test_document_reading()
    
    if not documents:
        print("\nâš ï¸  æ²¡æœ‰æ‰¾åˆ°æ–‡æ¡£ï¼Œè¯·å…ˆä¸Šä¼ æ–‡çŒ®")
        show_upload_instructions()
        return
    
    # æµ‹è¯•2: å‘é‡åŒ–
    index = test_vectorization(documents)
    
    # æµ‹è¯•3: æŸ¥è¯¢
    if index:
        test_query(index)
    
    # æ˜¾ç¤ºæ”¯æŒçš„æ ¼å¼
    test_supported_formats()
    
    # æ˜¾ç¤ºä¸Šä¼ è¯´æ˜
    show_upload_instructions()
    
    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("  1. ä¸Šä¼ æ›´å¤šPDFæ–‡çŒ®åˆ° food_research_data/papers/")
    print("  2. è¿è¡Œ python app.py å¯åŠ¨å®Œæ•´ç³»ç»Ÿ")
    print("  3. è®¿é—® http://localhost:5001 å¼€å§‹ä½¿ç”¨\n")

if __name__ == "__main__":
    main()
