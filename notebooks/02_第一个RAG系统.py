#!/usr/bin/env python3
"""
ç¬¬ä¸€ä¸ªé£Ÿå“AIç§‘ç ”é—®ç­”ç³»ç»Ÿ
è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„RAGç³»ç»Ÿç¤ºä¾‹ï¼Œä¸“é—¨ä¸ºé£Ÿå“ç§‘å­¦ç ”ç©¶è®¾è®¡
"""

import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒé…ç½®"""
    print("ğŸ” æ£€æŸ¥ç¯å¢ƒé…ç½®...")
    
    # æ£€æŸ¥DeepSeek APIå¯†é’¥
    deepseek_key = os.getenv('DEEPSEEK_API_KEY')
    openai_key = os.getenv('OPENAI_API_KEY')
    
    if deepseek_key and deepseek_key != "your_deepseek_api_key_here":
        print("âœ… DeepSeek APIå¯†é’¥å·²é…ç½®")
        print("ğŸš€ ä½¿ç”¨DeepSeek API (é«˜æ€§ä»·æ¯”é€‰æ‹©)")
    elif openai_key and openai_key != "your_openai_api_key_here":
        print("âœ… OpenAI APIå¯†é’¥å·²é…ç½®")
        print("ğŸš€ ä½¿ç”¨OpenAI API")
    else:
        print("âŒ è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®APIå¯†é’¥")
        print("ğŸ’¡ DeepSeek API: https://platform.deepseek.com/")
        print("ğŸ’¡ OpenAI API: https://platform.openai.com/api-keys")
        return False
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    data_dir = "food_research_data"
    if not os.path.exists(data_dir):
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return False
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£
    has_files = False
    for root, dirs, files in os.walk(data_dir):
        if files:
            has_files = True
            break
    
    if not has_files:
        print("âš ï¸  æ•°æ®ç›®å½•ä¸ºç©ºï¼Œè¯·æ·»åŠ ä¸€äº›é£Ÿå“ç§‘ç ”æ–‡æ¡£")
        print("ğŸ’¡ æ”¯æŒçš„æ ¼å¼: .txt, .pdf, .docx, .md")
        # åˆ›å»ºç¤ºä¾‹æ–‡æ¡£
        create_sample_documents()
    else:
        print("âœ… æ‰¾åˆ°ç ”ç©¶æ–‡æ¡£")
    
    return True

def create_sample_documents():
    """åˆ›å»ºç¤ºä¾‹é£Ÿå“ç§‘å­¦æ–‡æ¡£"""
    print("ğŸ“ åˆ›å»ºç¤ºä¾‹é£Ÿå“ç§‘å­¦æ–‡æ¡£...")
    
    sample_docs = {
        "food_research_data/papers/æŠ—æ°§åŒ–å‰‚ç ”ç©¶.txt": """
# é£Ÿå“ä¸­çš„æŠ—æ°§åŒ–å‰‚ç ”ç©¶

## æ¦‚è¿°
æŠ—æ°§åŒ–å‰‚æ˜¯èƒ½å¤Ÿé˜²æ­¢æˆ–å»¶ç¼“é£Ÿå“æ°§åŒ–çš„ç‰©è´¨ï¼Œåœ¨é£Ÿå“ä¿é²œå’Œè¥å…»ä¿æŒä¸­èµ·é‡è¦ä½œç”¨ã€‚

## ä¸»è¦ç±»å‹

### å¤©ç„¶æŠ—æ°§åŒ–å‰‚
1. **ç»´ç”Ÿç´ E (ç”Ÿè‚²é…š)**
   - è„‚æº¶æ€§æŠ—æ°§åŒ–å‰‚
   - ä¸»è¦å­˜åœ¨äºæ¤ç‰©æ²¹ã€åšæœä¸­
   - èƒ½æœ‰æ•ˆé˜²æ­¢è„‚è´¨è¿‡æ°§åŒ–

2. **ç»´ç”Ÿç´ C (æŠ—åè¡€é…¸)**
   - æ°´æº¶æ€§æŠ—æ°§åŒ–å‰‚
   - å¹¿æ³›å­˜åœ¨äºæ–°é²œæ°´æœè”¬èœä¸­
   - èƒ½æ¸…é™¤è‡ªç”±åŸºï¼Œé˜²æ­¢è¤å˜

3. **å¤šé…šç±»åŒ–åˆç‰©**
   - åŒ…æ‹¬èŠ±é’ç´ ã€å„¿èŒ¶ç´ ã€æ§²çš®ç´ ç­‰
   - å­˜åœ¨äºèŒ¶å¶ã€çº¢é…’ã€æµ†æœä¸­
   - å…·æœ‰å¼ºæŠ—æ°§åŒ–æ´»æ€§

### åˆæˆæŠ—æ°§åŒ–å‰‚
1. **BHT (ä¸åŸºç¾ŸåŸºç”²è‹¯)**
   - å¸¸ç”¨äºæ²¹è„‚é£Ÿå“
   - çƒ­ç¨³å®šæ€§å¥½

2. **BHA (ä¸åŸºç¾ŸåŸºèŒ´é¦™é†š)**
   - é€‚ç”¨äºåŠ¨ç‰©è„‚è‚ª
   - åœ¨é…¸æ€§æ¡ä»¶ä¸‹ç¨³å®š

## åº”ç”¨åŸç†
æŠ—æ°§åŒ–å‰‚é€šè¿‡ä»¥ä¸‹æœºåˆ¶å‘æŒ¥ä½œç”¨ï¼š
- æ¸…é™¤è‡ªç”±åŸº
- è¯åˆé‡‘å±ç¦»å­
- å†ç”Ÿå…¶ä»–æŠ—æ°§åŒ–å‰‚
- é˜»æ–­æ°§åŒ–é“¾ååº”

## åœ¨é£Ÿå“å·¥ä¸šä¸­çš„åº”ç”¨
- å»¶é•¿é£Ÿå“ä¿è´¨æœŸ
- ä¿æŒé£Ÿå“è¥å…»ä»·å€¼
- é˜²æ­¢é£Ÿå“å˜è‰²å˜å‘³
- æé«˜é£Ÿå“å®‰å…¨æ€§

## å‘å±•è¶‹åŠ¿
ç›®å‰ç ”ç©¶é‡ç‚¹è½¬å‘å¤©ç„¶æŠ—æ°§åŒ–å‰‚çš„å¼€å‘å’Œåº”ç”¨ï¼Œä»¥æ»¡è¶³æ¶ˆè´¹è€…å¯¹å¤©ç„¶ã€å¥åº·é£Ÿå“çš„éœ€æ±‚ã€‚
        """,
        
        "food_research_data/papers/é£Ÿå“å®‰å…¨æ£€æµ‹.txt": """
# é£Ÿå“å®‰å…¨æ£€æµ‹æŠ€æœ¯ç ”ç©¶

## å¼•è¨€
é£Ÿå“å®‰å…¨æ£€æµ‹æ˜¯ä¿éšœå…¬ä¼—å¥åº·çš„é‡è¦æ‰‹æ®µï¼Œæ¶‰åŠåŒ–å­¦æ±¡æŸ“ç‰©ã€å¾®ç”Ÿç‰©ã€æ·»åŠ å‰‚ç­‰å¤šä¸ªæ–¹é¢çš„æ£€æµ‹ã€‚

## ä¸»è¦æ£€æµ‹é¡¹ç›®

### åŒ–å­¦æ±¡æŸ“ç‰©æ£€æµ‹
1. **é‡é‡‘å±æ£€æµ‹**
   - é“…ã€æ±ã€é•‰ã€ç ·ç­‰
   - æ£€æµ‹æ–¹æ³•ï¼šåŸå­å¸æ”¶å…‰è°±æ³•ã€ICP-MS

2. **å†œè¯æ®‹ç•™æ£€æµ‹**
   - æœ‰æœºç£·ã€æœ‰æœºæ°¯ã€æ°¨åŸºç”²é…¸é…¯ç±»
   - æ£€æµ‹æ–¹æ³•ï¼šæ°”ç›¸è‰²è°±æ³•ã€æ¶²ç›¸è‰²è°±æ³•

3. **å…½è¯æ®‹ç•™æ£€æµ‹**
   - æŠ—ç”Ÿç´ ã€æ¿€ç´ ç±»è¯ç‰©
   - æ£€æµ‹æ–¹æ³•ï¼šELISAã€LC-MS/MS

### å¾®ç”Ÿç‰©æ£€æµ‹
1. **è‡´ç—…èŒæ£€æµ‹**
   - æ²™é—¨æ°èŒã€å¤§è‚ æ†èŒã€ææ–¯ç‰¹èŒ
   - æ£€æµ‹æ–¹æ³•ï¼šåŸ¹å…»æ³•ã€PCRæ³•ã€å…ç–«æ³•

2. **éœ‰èŒæ¯’ç´ æ£€æµ‹**
   - é»„æ›²éœ‰æ¯’ç´ ã€å‘•åæ¯’ç´ ã€ç‰ç±³èµ¤éœ‰çƒ¯é…®
   - æ£€æµ‹æ–¹æ³•ï¼šHPLCã€å…ç–«äº²å’ŒæŸ±æ³•

### é£Ÿå“æ·»åŠ å‰‚æ£€æµ‹
1. **é˜²è…å‰‚æ£€æµ‹**
   - è‹¯ç”²é…¸ã€å±±æ¢¨é…¸ã€ä¸™é…¸ç­‰
   - æ£€æµ‹æ–¹æ³•ï¼šHPLCæ³•

2. **ç”œå‘³å‰‚æ£€æµ‹**
   - ç³–ç²¾ã€å®‰èµ›èœœã€é˜¿æ–¯å·´ç”œ
   - æ£€æµ‹æ–¹æ³•ï¼šHPLCæ³•ã€ç¦»å­è‰²è°±æ³•

## å¿«é€Ÿæ£€æµ‹æŠ€æœ¯
1. **å…ç–«å±‚ææŠ€æœ¯**
   - æ“ä½œç®€ä¾¿ï¼Œç»“æœå¿«é€Ÿ
   - é€‚ç”¨äºç°åœºæ£€æµ‹

2. **ç”Ÿç‰©ä¼ æ„Ÿå™¨æŠ€æœ¯**
   - é«˜çµæ•åº¦ã€é«˜ç‰¹å¼‚æ€§
   - å¯å®ç°å®æ—¶ç›‘æµ‹

3. **æ‹‰æ›¼å…‰è°±æŠ€æœ¯**
   - æ— æŸæ£€æµ‹
   - å¯æ£€æµ‹å¤šç§æˆåˆ†

## å‘å±•è¶‹åŠ¿
- æ£€æµ‹æŠ€æœ¯å‘å¿«é€Ÿã€å‡†ç¡®ã€ä¾¿æºæ–¹å‘å‘å±•
- å¤šæŠ€æœ¯èåˆï¼Œæé«˜æ£€æµ‹æ•ˆç‡
- å»ºç«‹å®Œå–„çš„é£Ÿå“å®‰å…¨è¿½æº¯ä½“ç³»
        """,
        
        "food_research_data/datasets/è¥å…»æˆåˆ†æ•°æ®.txt": """
# å¸¸è§é£Ÿå“è¥å…»æˆåˆ†æ•°æ®

## è°·ç‰©ç±» (æ¯100g)
### å¤§ç±³
- èƒ½é‡: 346 kcal
- è›‹ç™½è´¨: 7.4 g
- è„‚è‚ª: 0.8 g
- ç¢³æ°´åŒ–åˆç‰©: 77.9 g
- è†³é£Ÿçº¤ç»´: 0.7 g

### å°éº¦ç²‰
- èƒ½é‡: 366 kcal
- è›‹ç™½è´¨: 11.2 g
- è„‚è‚ª: 1.3 g
- ç¢³æ°´åŒ–åˆç‰©: 75.0 g
- è†³é£Ÿçº¤ç»´: 2.8 g

## è”¬èœç±» (æ¯100g)
### è èœ
- èƒ½é‡: 28 kcal
- è›‹ç™½è´¨: 2.6 g
- è„‚è‚ª: 0.3 g
- ç¢³æ°´åŒ–åˆç‰©: 4.5 g
- ç»´ç”Ÿç´ C: 32 mg
- é“: 2.9 mg

### èƒ¡èåœ
- èƒ½é‡: 25 kcal
- è›‹ç™½è´¨: 1.0 g
- è„‚è‚ª: 0.2 g
- ç¢³æ°´åŒ–åˆç‰©: 6.0 g
- èƒ¡èåœç´ : 4010 Î¼g

## æ°´æœç±» (æ¯100g)
### è‹¹æœ
- èƒ½é‡: 54 kcal
- è›‹ç™½è´¨: 0.2 g
- è„‚è‚ª: 0.2 g
- ç¢³æ°´åŒ–åˆç‰©: 13.5 g
- ç»´ç”Ÿç´ C: 4 mg

### æ©™å­
- èƒ½é‡: 48 kcal
- è›‹ç™½è´¨: 0.8 g
- è„‚è‚ª: 0.2 g
- ç¢³æ°´åŒ–åˆç‰©: 11.1 g
- ç»´ç”Ÿç´ C: 33 mg

## è‚‰ç±» (æ¯100g)
### çŒªè‚‰(ç˜¦)
- èƒ½é‡: 143 kcal
- è›‹ç™½è´¨: 20.3 g
- è„‚è‚ª: 6.2 g
- é“: 3.0 mg
- é”Œ: 2.11 mg

### é¸¡èƒ¸è‚‰
- èƒ½é‡: 133 kcal
- è›‹ç™½è´¨: 19.4 g
- è„‚è‚ª: 5.0 g
- ç»´ç”Ÿç´ B6: 0.6 mg
        """
    }
    
    for filepath, content in sample_docs.items():
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"âœ… åˆ›å»º: {filepath}")

def build_rag_system():
    """æ„å»ºRAGç³»ç»Ÿ"""
    print("\nğŸ”¨ æ„å»ºé£Ÿå“AIç§‘ç ”é—®ç­”ç³»ç»Ÿ...")
    
    try:
        # å¯¼å…¥å¿…è¦çš„åº“
        from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
        from llama_index.core import Settings
        from llama_index.llms.openai import OpenAI
        from llama_index.embeddings.openai import OpenAIEmbedding
        
        print("âœ… æˆåŠŸå¯¼å…¥LlamaIndexåº“")
        
        # æ£€æŸ¥ä½¿ç”¨å“ªä¸ªAPI
        deepseek_key = os.getenv('DEEPSEEK_API_KEY')
        openai_key = os.getenv('OPENAI_API_KEY')
        
        if deepseek_key and deepseek_key != "your_deepseek_api_key_here":
            # ä½¿ç”¨DeepSeek API
            print("ğŸš€ é…ç½®DeepSeek API...")
            Settings.llm = OpenAI(
                model="gpt-3.5-turbo",  # ä½¿ç”¨å…¼å®¹çš„æ¨¡å‹å
                api_key=deepseek_key,
                api_base="https://api.deepseek.com/v1",  # æ·»åŠ /v1è·¯å¾„
                temperature=0.1,
                is_chat_model=True,
                system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é£Ÿå“ç§‘å­¦ç ”ç©¶åŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼Œ
                å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚å›ç­”è¦å‡†ç¡®ã€ä¸“ä¸šï¼Œå¹¶ä¸”æ˜“äºç†è§£ã€‚"""
            )
            
            # ä½¿ç”¨æœ¬åœ°ä¸­æ–‡åµŒå…¥æ¨¡å‹ï¼ˆå…è´¹ä¸”é«˜è´¨é‡ï¼‰
            from llama_index.embeddings.huggingface import HuggingFaceEmbedding
            print("ğŸ“¥ åŠ è½½æœ¬åœ°ä¸­æ–‡åµŒå…¥æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œä¼šä¸‹è½½ï¼Œçº¦400MBï¼‰...")
            Settings.embed_model = HuggingFaceEmbedding(
                model_name="BAAI/bge-small-zh-v1.5",  # ä¸­æ–‡ä¼˜åŒ–çš„åµŒå…¥æ¨¡å‹
                cache_folder="./models"  # æ¨¡å‹ç¼“å­˜ç›®å½•
            )
            print("âœ… é…ç½®DeepSeek LLM + æœ¬åœ°ä¸­æ–‡åµŒå…¥æ¨¡å‹")
            
        elif openai_key and openai_key != "your_openai_api_key_here":
            # ä½¿ç”¨OpenAI API
            print("ğŸš€ é…ç½®OpenAI API...")
            Settings.llm = OpenAI(
                model="gpt-3.5-turbo",
                temperature=0.1,
                system_prompt="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é£Ÿå“ç§‘å­¦ç ”ç©¶åŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼Œ
                å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚å›ç­”è¦å‡†ç¡®ã€ä¸“ä¸šï¼Œå¹¶ä¸”æ˜“äºç†è§£ã€‚"""
            )
            
            Settings.embed_model = OpenAIEmbedding(
                model="text-embedding-ada-002"
            )
            print("âœ… é…ç½®OpenAI LLMå’ŒåµŒå…¥æ¨¡å‹")
        else:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„APIå¯†é’¥")
            return None
        
        # åŠ è½½æ–‡æ¡£
        print("ğŸ“š åŠ è½½é£Ÿå“ç§‘ç ”æ–‡æ¡£...")
        documents = SimpleDirectoryReader(
            "food_research_data",
            recursive=True
        ).load_data()
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
        
        # æ„å»ºå‘é‡ç´¢å¼•
        print("ğŸ” æ„å»ºå‘é‡ç´¢å¼•...")
        index = VectorStoreIndex.from_documents(documents)
        print("âœ… å‘é‡ç´¢å¼•æ„å»ºå®Œæˆ")
        
        # åˆ›å»ºæŸ¥è¯¢å¼•æ“
        query_engine = index.as_query_engine(
            similarity_top_k=3,  # è¿”å›æœ€ç›¸å…³çš„3ä¸ªæ–‡æ¡£ç‰‡æ®µ
            response_mode="compact"  # ç´§å‡‘çš„å›ç­”æ¨¡å¼
        )
        print("âœ… æŸ¥è¯¢å¼•æ“åˆ›å»ºå®Œæˆ")
        
        return query_engine
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿å·²å®‰è£…llama-index: pip install llama-index")
        return None
    except Exception as e:
        print(f"âŒ æ„å»ºå¤±è´¥: {e}")
        return None

def test_rag_system(query_engine):
    """æµ‹è¯•RAGç³»ç»Ÿ"""
    print("\nğŸ§ª æµ‹è¯•é£Ÿå“AIç§‘ç ”é—®ç­”ç³»ç»Ÿ...")
    
    test_questions = [
        "é£Ÿå“ä¸­æœ‰å“ªäº›ä¸»è¦çš„å¤©ç„¶æŠ—æ°§åŒ–å‰‚ï¼Ÿ",
        "é£Ÿå“å®‰å…¨æ£€æµ‹ä¸»è¦æ£€æµ‹å“ªäº›é¡¹ç›®ï¼Ÿ",
        "è‹¹æœå’Œæ©™å­çš„è¥å…»æˆåˆ†æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
        "ä»€ä¹ˆæ˜¯ç»´ç”Ÿç´ Eï¼Ÿå®ƒåœ¨é£Ÿå“ä¸­çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ",
        "é£Ÿå“å®‰å…¨æ£€æµ‹çš„å‘å±•è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ"
    ]
    
    print("ğŸ“ æµ‹è¯•é—®é¢˜:")
    for i, question in enumerate(test_questions, 1):
        print(f"{i}. {question}")
    
    print("\n" + "="*60)
    
    for i, question in enumerate(test_questions, 1):
        print(f"\nğŸ¤” é—®é¢˜ {i}: {question}")
        print("-" * 40)
        
        try:
            response = query_engine.query(question)
            print(f"ğŸ¤– å›ç­”: {response}")
            
            # æ˜¾ç¤ºç›¸å…³æ–‡æ¡£æ¥æº
            if hasattr(response, 'source_nodes') and response.source_nodes:
                print("\nğŸ“š å‚è€ƒæ–‡æ¡£:")
                for j, node in enumerate(response.source_nodes, 1):
                    filename = node.metadata.get('file_name', 'æœªçŸ¥æ–‡æ¡£')
                    print(f"   {j}. {filename}")
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
        
        print("\n" + "="*60)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ é£Ÿå“AIç§‘ç ”é—®ç­”ç³»ç»Ÿå¯åŠ¨")
    print("="*50)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        return
    
    # æ„å»ºRAGç³»ç»Ÿ
    query_engine = build_rag_system()
    if not query_engine:
        return
    
    # æµ‹è¯•ç³»ç»Ÿ
    test_rag_system(query_engine)
    
    print("\nğŸ‰ ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")
    print("\nğŸ’¡ æ¥ä¸‹æ¥ä½ å¯ä»¥:")
    print("1. æ·»åŠ æ›´å¤šé£Ÿå“ç§‘ç ”æ–‡æ¡£åˆ° food_research_data/ ç›®å½•")
    print("2. åœ¨Jupyter notebookä¸­äº¤äº’å¼ä½¿ç”¨è¿™ä¸ªç³»ç»Ÿ")
    print("3. æ ¹æ®ä½ çš„ç ”ç©¶éœ€æ±‚å®šåˆ¶æŸ¥è¯¢å’Œå›ç­”")
    print("4. å°è¯•ä¸åŒçš„æŸ¥è¯¢ç­–ç•¥å’Œå‚æ•°ä¼˜åŒ–")

if __name__ == "__main__":
    main()