#!/usr/bin/env python3
"""å¢é‡ç´¢å¼•ç®¡ç†å™¨ - åªå¤„ç†æ–°æ·»åŠ çš„æ–‡çŒ®"""

import os
import json
from pathlib import Path
from typing import List, Set
from llama_index.core import SimpleDirectoryReader
from persistent_storage import rag_system
from pdf_metadata_extractor import PDFMetadataExtractor
from metadata_storage import MetadataStorage

class IncrementalIndexer:
    """å¢é‡ç´¢å¼•ç®¡ç†å™¨"""
    
    def __init__(self, 
                 data_dir: str = "./food_research_data",
                 tracking_file: str = "./storage/indexed_files.json"):
        self.data_dir = data_dir
        self.tracking_file = tracking_file
        self.indexed_files = self._load_tracking()
        self.metadata_extractor = PDFMetadataExtractor()
        self.metadata_storage = MetadataStorage()
    
    def _load_tracking(self) -> Set[str]:
        """åŠ è½½å·²ç´¢å¼•æ–‡ä»¶åˆ—è¡¨"""
        if os.path.exists(self.tracking_file):
            try:
                with open(self.tracking_file, 'r', encoding='utf-8') as f:
                    return set(json.load(f))
            except Exception as e:
                print(f"åŠ è½½è·Ÿè¸ªæ–‡ä»¶å¤±è´¥: {e}")
                return set()
        return set()
    
    def _save_tracking(self):
        """ä¿å­˜å·²ç´¢å¼•æ–‡ä»¶åˆ—è¡¨"""
        os.makedirs(os.path.dirname(self.tracking_file), exist_ok=True)
        with open(self.tracking_file, 'w', encoding='utf-8') as f:
            json.dump(list(self.indexed_files), f, indent=2, ensure_ascii=False)
    
    def get_all_files(self) -> List[str]:
        """è·å–æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶"""
        all_files = []
        supported_extensions = ('.pdf', '.docx', '.txt', '.md', '.csv', '.json')
        
        for root, dirs, files in os.walk(self.data_dir):
            for f in files:
                if f.startswith('.'):
                    continue
                if f.lower().endswith(supported_extensions):
                    full_path = os.path.abspath(os.path.join(root, f))
                    all_files.append(full_path)
        
        return all_files
    
    def get_new_files(self) -> List[str]:
        """æ£€æµ‹æ–°æ–‡ä»¶"""
        all_files = self.get_all_files()
        new_files = [f for f in all_files if f not in self.indexed_files]
        return new_files
    
    def extract_metadata_for_new_files(self, new_files: List[str]):
        """ä¸ºæ–°PDFæ–‡ä»¶æå–å…ƒæ•°æ®"""
        pdf_count = 0
        for file_path in new_files:
            if file_path.lower().endswith('.pdf'):
                try:
                    if not self.metadata_storage.has_metadata(file_path):
                        print(f"æå–å…ƒæ•°æ®: {os.path.basename(file_path)}")
                        metadata = self.metadata_extractor.extract_metadata(file_path)
                        self.metadata_storage.save_metadata(file_path, metadata)
                        pdf_count += 1
                except Exception as e:
                    print(f"å…ƒæ•°æ®æå–å¤±è´¥ {file_path}: {e}")
        
        if pdf_count > 0:
            print(f"æˆåŠŸæå– {pdf_count} ä¸ªPDFæ–‡ä»¶çš„å…ƒæ•°æ®")
    
    def add_new_documents(self) -> bool:
        """å¢é‡æ·»åŠ æ–°æ–‡æ¡£åˆ°ç´¢å¼•"""
        print("=" * 60)
        print("å¢é‡ç´¢å¼•æ›´æ–°")
        print("=" * 60)
        
        # æ£€æµ‹æ–°æ–‡ä»¶
        new_files = self.get_new_files()
        
        if not new_files:
            print("âœ… æ²¡æœ‰æ–°æ–‡ä»¶éœ€è¦ç´¢å¼•")
            return True
        
        print(f"\nğŸ“ å‘ç° {len(new_files)} ä¸ªæ–°æ–‡ä»¶:")
        for f in new_files[:5]:
            print(f"   - {os.path.basename(f)}")
        if len(new_files) > 5:
            print(f"   ... è¿˜æœ‰ {len(new_files) - 5} ä¸ªæ–‡ä»¶")
        
        # ç¡®ä¿ç´¢å¼•å·²åˆå§‹åŒ–
        if rag_system.index is None:
            print("\nâš ï¸  ç´¢å¼•æœªåˆå§‹åŒ–ï¼Œæ­£åœ¨åŠ è½½...")
            rag_system.load_or_create_index()
        
        # æå–å…ƒæ•°æ®
        print("\nğŸ“Š æå–PDFå…ƒæ•°æ®...")
        self.extract_metadata_for_new_files(new_files)
        
        # è¯»å–æ–°æ–‡ä»¶
        print("\nğŸ“– è¯»å–æ–°æ–‡æ¡£...")
        reader = SimpleDirectoryReader(input_files=new_files)
        new_docs = reader.load_data()
        print(f"âœ… è¯»å–åˆ° {len(new_docs)} ä¸ªæ–‡æ¡£å—")
        
        # å¢é‡æ·»åŠ åˆ°ç´¢å¼•
        print("\nğŸ”„ æ·»åŠ åˆ°ç´¢å¼•...")
        success = rag_system.add_documents(new_docs)
        
        if success:
            # æ›´æ–°è·Ÿè¸ªåˆ—è¡¨
            self.indexed_files.update(new_files)
            self._save_tracking()
            print("\nâœ… å¢é‡ç´¢å¼•æ›´æ–°æˆåŠŸï¼")
            print(f"ğŸ“Š å½“å‰å·²ç´¢å¼•æ–‡ä»¶æ•°: {len(self.indexed_files)}")
        else:
            print("\nâŒ å¢é‡ç´¢å¼•æ›´æ–°å¤±è´¥")
        
        print("=" * 60)
        return success
    
    def rebuild_tracking(self):
        """é‡å»ºè·Ÿè¸ªæ–‡ä»¶ï¼ˆåŸºäºå½“å‰æ‰€æœ‰æ–‡ä»¶ï¼‰"""
        all_files = self.get_all_files()
        self.indexed_files = set(all_files)
        self._save_tracking()
        print(f"âœ… è·Ÿè¸ªæ–‡ä»¶å·²é‡å»ºï¼Œå…± {len(all_files)} ä¸ªæ–‡ä»¶")

# å‘½ä»¤è¡Œä½¿ç”¨
if __name__ == "__main__":
    import sys
    
    indexer = IncrementalIndexer()
    
    if len(sys.argv) > 1 and sys.argv[1] == "--rebuild-tracking":
        # é‡å»ºè·Ÿè¸ªæ–‡ä»¶
        indexer.rebuild_tracking()
    else:
        # å¢é‡æ·»åŠ æ–°æ–‡æ¡£
        indexer.add_new_documents()
