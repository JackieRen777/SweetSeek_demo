# ğŸ§  æœ¬åœ°åµŒå…¥æ¨¡å‹è¯¦è§£

## ä»€ä¹ˆæ˜¯åµŒå…¥æ¨¡å‹ï¼Ÿ

**åµŒå…¥æ¨¡å‹ï¼ˆEmbedding Modelï¼‰**æ˜¯å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—å‘é‡çš„AIæ¨¡å‹ï¼Œè¿™äº›å‘é‡èƒ½å¤Ÿæ•æ‰æ–‡æœ¬çš„è¯­ä¹‰ä¿¡æ¯ã€‚

### ç®€å•ç±»æ¯”
æƒ³è±¡ä½ è¦åœ¨å›¾ä¹¦é¦†æ‰¾ç›¸å…³çš„ä¹¦ï¼š
- **ä¼ ç»Ÿæ–¹æ³•**ï¼šæŒ‰å…³é”®è¯æœç´¢ï¼ˆåªèƒ½æ‰¾åˆ°åŒ…å«ç›¸åŒè¯çš„ä¹¦ï¼‰
- **åµŒå…¥æ¨¡å‹**ï¼šç†è§£ä¹¦çš„"æ„æ€"ï¼Œæ‰¾åˆ°æ„æ€ç›¸è¿‘çš„ä¹¦

```
æ–‡æœ¬: "è‹¹æœå¯Œå«ç»´ç”Ÿç´ C"
     â†“ (åµŒå…¥æ¨¡å‹)
å‘é‡: [0.23, -0.45, 0.67, ..., 0.12]  (768ç»´æ•°å­—)

æ–‡æœ¬: "æ©™å­å«æœ‰å¤§é‡æŠ—åè¡€é…¸"
     â†“ (åµŒå…¥æ¨¡å‹)
å‘é‡: [0.21, -0.43, 0.69, ..., 0.14]  (ç›¸ä¼¼çš„å‘é‡)
```

## ğŸ¯ åœ¨RAGç³»ç»Ÿä¸­çš„ä½œç”¨

### 1. æ–‡æ¡£ç´¢å¼•é˜¶æ®µ
```python
æ–‡æ¡£1: "æŠ—æ°§åŒ–å‰‚èƒ½é˜²æ­¢é£Ÿå“æ°§åŒ–" â†’ å‘é‡1: [0.1, 0.2, ...]
æ–‡æ¡£2: "ç»´ç”Ÿç´ Eæ˜¯è„‚æº¶æ€§æŠ—æ°§åŒ–å‰‚" â†’ å‘é‡2: [0.15, 0.18, ...]
æ–‡æ¡£3: "é£Ÿå“å®‰å…¨æ£€æµ‹å¾ˆé‡è¦" â†’ å‘é‡3: [0.8, 0.3, ...]
```

### 2. æŸ¥è¯¢é˜¶æ®µ
```python
ç”¨æˆ·é—®é¢˜: "ä»€ä¹ˆæ˜¯æŠ—æ°§åŒ–å‰‚ï¼Ÿ" â†’ æŸ¥è¯¢å‘é‡: [0.12, 0.19, ...]
```

### 3. æ£€ç´¢é˜¶æ®µ
```python
è®¡ç®—ç›¸ä¼¼åº¦:
- æŸ¥è¯¢å‘é‡ vs å‘é‡1: ç›¸ä¼¼åº¦ 0.95 âœ… æœ€ç›¸å…³
- æŸ¥è¯¢å‘é‡ vs å‘é‡2: ç›¸ä¼¼åº¦ 0.88 âœ… ç›¸å…³
- æŸ¥è¯¢å‘é‡ vs å‘é‡3: ç›¸ä¼¼åº¦ 0.23 âŒ ä¸ç›¸å…³
```

## ğŸŒ APIåµŒå…¥ vs æœ¬åœ°åµŒå…¥

### APIåµŒå…¥ï¼ˆå¦‚OpenAI text-embedding-ada-002ï¼‰

**ä¼˜ç‚¹ï¼š**
- âœ… è´¨é‡éå¸¸é«˜
- âœ… æ— éœ€ä¸‹è½½æ¨¡å‹
- âœ… å³å¼€å³ç”¨

**ç¼ºç‚¹ï¼š**
- âŒ éœ€è¦ä»˜è´¹ï¼ˆçº¦$0.0001/1K tokensï¼‰
- âŒ éœ€è¦ç½‘ç»œè¿æ¥
- âŒ æ•°æ®å‘é€åˆ°äº‘ç«¯ï¼ˆéšç§é—®é¢˜ï¼‰
- âŒ æœ‰APIè°ƒç”¨é™åˆ¶

### æœ¬åœ°åµŒå…¥ï¼ˆå¦‚BAAI/bge-small-zh-v1.5ï¼‰

**ä¼˜ç‚¹ï¼š**
- âœ… å®Œå…¨å…è´¹
- âœ… æ•°æ®éšç§ä¿æŠ¤ï¼ˆæœ¬åœ°å¤„ç†ï¼‰
- âœ… ç¦»çº¿å¯ç”¨
- âœ… æ— APIè°ƒç”¨é™åˆ¶
- âœ… ä¸­æ–‡æ•ˆæœæ›´å¥½

**ç¼ºç‚¹ï¼š**
- âŒ éœ€è¦ä¸‹è½½æ¨¡å‹ï¼ˆçº¦400MBï¼‰
- âŒ é¦–æ¬¡è¿è¡Œè¾ƒæ…¢ï¼ˆä¸‹è½½æ—¶é—´ï¼‰
- âŒ å ç”¨æœ¬åœ°å­˜å‚¨ç©ºé—´

## ğŸ‡¨ğŸ‡³ æ¨èçš„ä¸­æ–‡åµŒå…¥æ¨¡å‹

### 1. BAAI/bge-small-zh-v1.5 â­ æ¨è
```python
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

embed_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-small-zh-v1.5"
)
```

**ç‰¹ç‚¹ï¼š**
- æ¨¡å‹å¤§å°ï¼šçº¦400MB
- å‘é‡ç»´åº¦ï¼š512ç»´
- ä¸­æ–‡ä¼˜åŒ–ï¼šä¸“é—¨é’ˆå¯¹ä¸­æ–‡è®­ç»ƒ
- æ€§èƒ½ï¼šåœ¨ä¸­æ–‡ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜ç§€
- é€Ÿåº¦ï¼šå¿«é€Ÿ

### 2. BAAI/bge-large-zh-v1.5
```python
embed_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-large-zh-v1.5"
)
```

**ç‰¹ç‚¹ï¼š**
- æ¨¡å‹å¤§å°ï¼šçº¦1.3GB
- å‘é‡ç»´åº¦ï¼š1024ç»´
- è´¨é‡æ›´é«˜ï¼Œä½†é€Ÿåº¦è¾ƒæ…¢

### 3. sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
```python
embed_model = HuggingFaceEmbedding(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
)
```

**ç‰¹ç‚¹ï¼š**
- å¤šè¯­è¨€æ”¯æŒ
- ä¸­è‹±æ–‡æ··åˆæ–‡æ¡£æ•ˆæœå¥½

## ğŸ’» ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨
```python
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

# åˆ›å»ºåµŒå…¥æ¨¡å‹
embed_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-small-zh-v1.5",
    cache_folder="./models"  # æ¨¡å‹ç¼“å­˜ç›®å½•
)

# åµŒå…¥å•ä¸ªæ–‡æœ¬
text = "é£Ÿå“ä¸­çš„æŠ—æ°§åŒ–å‰‚"
embedding = embed_model.get_text_embedding(text)
print(f"å‘é‡ç»´åº¦: {len(embedding)}")  # 512

# åµŒå…¥å¤šä¸ªæ–‡æœ¬
texts = ["æŠ—æ°§åŒ–å‰‚", "ç»´ç”Ÿç´ C", "é£Ÿå“å®‰å…¨"]
embeddings = embed_model.get_text_embedding_batch(texts)
```

### åœ¨RAGç³»ç»Ÿä¸­ä½¿ç”¨
```python
from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

# é…ç½®æœ¬åœ°åµŒå…¥æ¨¡å‹
Settings.embed_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-small-zh-v1.5"
)

# åŠ è½½æ–‡æ¡£å¹¶æ„å»ºç´¢å¼•
documents = SimpleDirectoryReader("food_research_data").load_data()
index = VectorStoreIndex.from_documents(documents)

# æŸ¥è¯¢
query_engine = index.as_query_engine()
response = query_engine.query("ä»€ä¹ˆæ˜¯æŠ—æ°§åŒ–å‰‚ï¼Ÿ")
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æ¨¡å‹ | å¤§å° | ç»´åº¦ | ä¸­æ–‡æ•ˆæœ | é€Ÿåº¦ | æˆæœ¬ |
|------|------|------|----------|------|------|
| OpenAI ada-002 | API | 1536 | â­â­â­â­ | å¿« | ä»˜è´¹ |
| bge-small-zh | 400MB | 512 | â­â­â­â­â­ | å¿« | å…è´¹ |
| bge-large-zh | 1.3GB | 1024 | â­â­â­â­â­ | ä¸­ | å…è´¹ |
| multilingual-MiniLM | 470MB | 384 | â­â­â­â­ | å¿« | å…è´¹ |

## ğŸš€ é¦–æ¬¡è¿è¡Œ

### ä¸‹è½½è¿‡ç¨‹
```bash
python notebooks/02_ç¬¬ä¸€ä¸ªRAGç³»ç»Ÿ.py

# è¾“å‡ºï¼š
ğŸ“¥ åŠ è½½æœ¬åœ°ä¸­æ–‡åµŒå…¥æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œä¼šä¸‹è½½ï¼Œçº¦400MBï¼‰...
Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400MB/400MB [02:30<00:00, 2.67MB/s]
âœ… é…ç½®DeepSeek LLM + æœ¬åœ°ä¸­æ–‡åµŒå…¥æ¨¡å‹
```

### æ¨¡å‹å­˜å‚¨ä½ç½®
```
./models/
â””â”€â”€ BAAI/
    â””â”€â”€ bge-small-zh-v1.5/
        â”œâ”€â”€ config.json
        â”œâ”€â”€ pytorch_model.bin
        â””â”€â”€ tokenizer files...
```

## ğŸ”§ å¸¸è§é—®é¢˜

### Q: é¦–æ¬¡ä¸‹è½½å¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ
A: å¯ä»¥ä½¿ç”¨å›½å†…é•œåƒï¼š
```python
import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
```

### Q: å¦‚ä½•åˆ‡æ¢ä¸åŒçš„åµŒå…¥æ¨¡å‹ï¼Ÿ
A: ä¿®æ”¹ `model_name` å‚æ•°ï¼š
```python
# å°æ¨¡å‹ï¼ˆå¿«é€Ÿï¼‰
Settings.embed_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-small-zh-v1.5"
)

# å¤§æ¨¡å‹ï¼ˆé«˜è´¨é‡ï¼‰
Settings.embed_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-large-zh-v1.5"
)
```

### Q: æœ¬åœ°æ¨¡å‹å ç”¨å¤šå°‘å†…å­˜ï¼Ÿ
A: 
- bge-small-zh: çº¦500MBå†…å­˜
- bge-large-zh: çº¦1.5GBå†…å­˜

### Q: å¯ä»¥åˆ é™¤ä¸‹è½½çš„æ¨¡å‹å—ï¼Ÿ
A: å¯ä»¥ï¼Œåˆ é™¤ `./models/` ç›®å½•å³å¯ï¼Œä¸‹æ¬¡è¿è¡Œä¼šé‡æ–°ä¸‹è½½ã€‚

### Q: æœ¬åœ°åµŒå…¥æ¨¡å‹æ”¯æŒGPUåŠ é€Ÿå—ï¼Ÿ
A: æ”¯æŒï¼å¦‚æœæœ‰NVIDIA GPUï¼š
```python
embed_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-small-zh-v1.5",
    device="cuda"  # ä½¿ç”¨GPU
)
```

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„æ¨¡å‹
- **å­¦ä¹ é˜¶æ®µ**ï¼šä½¿ç”¨ bge-small-zhï¼ˆå¿«é€Ÿã€å¤Ÿç”¨ï¼‰
- **ç”Ÿäº§ç¯å¢ƒ**ï¼šä½¿ç”¨ bge-large-zhï¼ˆé«˜è´¨é‡ï¼‰
- **å¤šè¯­è¨€**ï¼šä½¿ç”¨ multilingual-MiniLM

### 2. ç¼“å­˜æ¨¡å‹
```python
# æŒ‡å®šç¼“å­˜ç›®å½•ï¼Œé¿å…é‡å¤ä¸‹è½½
embed_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-small-zh-v1.5",
    cache_folder="./models"
)
```

### 3. æ‰¹é‡å¤„ç†
```python
# æ‰¹é‡åµŒå…¥æ•ˆç‡æ›´é«˜
texts = [doc.text for doc in documents]
embeddings = embed_model.get_text_embedding_batch(texts)
```

## ğŸ¯ æ€»ç»“

**å¯¹äºä½ çš„é£Ÿå“ç§‘ç ”é¡¹ç›®ï¼Œæ¨èä½¿ç”¨ï¼š**

âœ… **DeepSeek API** (LLM) + **bge-small-zh-v1.5** (åµŒå…¥)

**åŸå› ï¼š**
1. DeepSeekä¾¿å®œä¸”ä¸­æ–‡èƒ½åŠ›å¼º
2. æœ¬åœ°åµŒå…¥æ¨¡å‹å…è´¹ä¸”éšç§å®‰å…¨
3. bge-small-zhä¸“é—¨é’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–
4. ç»„åˆä½¿ç”¨æ€§ä»·æ¯”æœ€é«˜

---

**ç°åœ¨è¿è¡Œç³»ç»Ÿï¼Œä½“éªŒæœ¬åœ°åµŒå…¥æ¨¡å‹çš„å¼ºå¤§ï¼** ğŸš€