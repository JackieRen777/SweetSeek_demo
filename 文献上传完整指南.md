# ğŸ“š æ–‡çŒ®ä¸Šä¼ å’Œå‘é‡åŒ–å®Œæ•´æŒ‡å—

## ğŸ¯ æ ¸å¿ƒç­”æ¡ˆ

### âŒ ä¸éœ€è¦è½¬æ¢ä¸ºMarkdownï¼
**LlamaIndexä¼šè‡ªåŠ¨å¤„ç†PDFã€Wordç­‰æ ¼å¼ï¼Œç›´æ¥ä¸Šä¼ å³å¯ï¼**

---

## ğŸ“ ä¸Šä¼ ä½ç½®

### æ–¹å¼1: ç›´æ¥æ”¾å…¥æ–‡ä»¶å¤¹ï¼ˆæœ€ç®€å•ï¼‰

```bash
# è®ºæ–‡ç±»æ–‡çŒ®
food_research_data/papers/

# æ•°æ®é›†ç±»æ–‡çŒ®
food_research_data/datasets/
```

**æ”¯æŒçš„æ ¼å¼ï¼š**
- âœ… PDF (.pdf)
- âœ… Word (.doc, .docx)
- âœ… æ–‡æœ¬ (.txt)
- âœ… Markdown (.md)
- âœ… CSV (.csv)
- âœ… JSON (.json)

**æ“ä½œæ­¥éª¤ï¼š**
```bash
# 1. å¤åˆ¶PDFåˆ°papersç›®å½•
cp ä½ çš„è®ºæ–‡.pdf food_research_data/papers/

# 2. æŸ¥çœ‹å·²ä¸Šä¼ çš„æ–‡ä»¶
ls food_research_data/papers/

# 3. é‡å¯åº”ç”¨ï¼ˆä¼šè‡ªåŠ¨å‘é‡åŒ–ï¼‰
python app.py
```

---

### æ–¹å¼2: Webç•Œé¢ä¸Šä¼ ï¼ˆæ¨èï¼‰

**æ­¥éª¤ï¼š**

1. **å¯åŠ¨ç³»ç»Ÿ**
```bash
python app.py
```

2. **è®¿é—®ä¸Šä¼ é¡µé¢**
```
http://localhost:5001/upload.html
```

3. **é€‰æ‹©æ–‡ä»¶å¹¶ä¸Šä¼ **
   - é€‰æ‹©æ–‡æ¡£ç±»å‹ï¼ˆè®ºæ–‡/æ•°æ®é›†ï¼‰
   - ç‚¹å‡»"é€‰æ‹©æ–‡ä»¶"
   - æ”¯æŒæ‰¹é‡ä¸Šä¼ 
   - ç‚¹å‡»"ä¸Šä¼ "
   - **ç³»ç»Ÿä¼šè‡ªåŠ¨å‘é‡åŒ–ï¼**

---

## ğŸ”„ å‘é‡åŒ–è¿‡ç¨‹ï¼ˆè‡ªåŠ¨å®Œæˆï¼‰

### å®Œæ•´æµç¨‹

```
PDFæ–‡ä»¶
    â†“
[1. æ–‡æœ¬æå–] â†’ LlamaIndexè‡ªåŠ¨æå–PDFå†…å®¹
    â†“
[2. æ–‡æœ¬åˆ†å—] â†’ åˆ‡åˆ†ä¸ºå°æ®µï¼ˆchunk_size=512ï¼‰
    â†“
[3. å‘é‡åŒ–] â†’ æœ¬åœ°åµŒå…¥æ¨¡å‹è½¬æ¢ä¸ºå‘é‡
    â†“
[4. å­˜å‚¨] â†’ ä¿å­˜åˆ°å‘é‡æ•°æ®åº“
    â†“
å®Œæˆï¼å¯ä»¥æŸ¥è¯¢
```

### ä»£ç å®ç°ï¼ˆå·²è‡ªåŠ¨å®Œæˆï¼‰

```python
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex

# 1. è‡ªåŠ¨è¯»å–æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
documents = SimpleDirectoryReader(
    "food_research_data",
    recursive=True  # é€’å½’è¯»å–å­ç›®å½•
).load_data()

# 2. è‡ªåŠ¨å‘é‡åŒ–å¹¶æ„å»ºç´¢å¼•
index = VectorStoreIndex.from_documents(documents)

# å°±è¿™ä¹ˆç®€å•ï¼PDFå·²ç»è¢«å‘é‡åŒ–äº†
```

---

## ğŸ“„ PDFå¤„ç†è¯¦è§£

### LlamaIndexå¦‚ä½•å¤„ç†PDFï¼Ÿ

**å†…ç½®æ”¯æŒï¼š**
```python
# è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç±»å‹å¹¶ä½¿ç”¨å¯¹åº”çš„è§£æå™¨
SimpleDirectoryReader("food_research_data")
```

**æ”¯æŒçš„PDFç±»å‹ï¼š**
- âœ… æ–‡æœ¬å‹PDFï¼ˆå¯å¤åˆ¶æ–‡å­—ï¼‰
- âœ… æ‰«æå‹PDFï¼ˆéœ€è¦OCRï¼Œè§ä¸‹æ–‡ï¼‰
- âœ… æ··åˆå‹PDF

### å¢å¼ºPDFå¤„ç†ï¼ˆå¯é€‰ï¼‰

å¦‚æœé‡åˆ°å¤æ‚PDFï¼Œå¯ä»¥å®‰è£…å¢å¼ºåº“ï¼š

```bash
# æ–¹æ¡ˆ1: PyPDFï¼ˆé»˜è®¤ï¼Œå·²åŒ…å«ï¼‰
pip install pypdf

# æ–¹æ¡ˆ2: PDFMinerï¼ˆæ›´å¼ºå¤§ï¼‰
pip install pdfminer.six

# æ–¹æ¡ˆ3: PyMuPDFï¼ˆæœ€å¿«ï¼‰
pip install pymupdf

# æ–¹æ¡ˆ4: OCRæ”¯æŒï¼ˆæ‰«æç‰ˆPDFï¼‰
pip install pytesseract
```

**ä½¿ç”¨å¢å¼ºè§£æå™¨ï¼š**
```python
from llama_index.readers.file import PDFReader

# ä½¿ç”¨ä¸“é—¨çš„PDFé˜…è¯»å™¨
pdf_reader = PDFReader()
documents = pdf_reader.load_data(file="paper.pdf")
```

---

## ğŸ” å®é™…æ¼”ç¤º

### ç¤ºä¾‹1: ä¸Šä¼ å•ä¸ªPDF

```bash
# 1. å¤åˆ¶PDF
cp "é£Ÿå“æ·»åŠ å‰‚ç ”ç©¶.pdf" food_research_data/papers/

# 2. æŸ¥çœ‹æ–‡ä»¶
ls food_research_data/papers/
# è¾“å‡º: é£Ÿå“æ·»åŠ å‰‚ç ”ç©¶.pdf

# 3. å¯åŠ¨ç³»ç»Ÿï¼ˆè‡ªåŠ¨å‘é‡åŒ–ï¼‰
python app.py
```

**ç³»ç»Ÿè¾“å‡ºï¼š**
```
[æ„å»º] é¦–æ¬¡è¿è¡Œï¼Œæ„å»ºæ–°ç´¢å¼•...
[åŠ è½½] è¯»å–äº† 3 ä¸ªæ–‡æ¡£
  - æŠ—æ°§åŒ–å‰‚ç ”ç©¶.txt
  - é£Ÿå“å®‰å…¨æ£€æµ‹.txt
  - é£Ÿå“æ·»åŠ å‰‚ç ”ç©¶.pdf  â† è‡ªåŠ¨è¯†åˆ«PDF
[å‘é‡åŒ–] ä½¿ç”¨ bge-small-zh-v1.5 æ¨¡å‹...
[ä¿å­˜] ç´¢å¼•å·²ä¿å­˜åˆ° ./storage
[æˆåŠŸ] ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ
```

---

### ç¤ºä¾‹2: æ‰¹é‡ä¸Šä¼ å¤šä¸ªæ–‡çŒ®

```bash
# åˆ›å»ºä¸´æ—¶ç›®å½•
mkdir temp_papers

# å¤åˆ¶æ‰€æœ‰PDF
cp *.pdf temp_papers/

# ç§»åŠ¨åˆ°papersç›®å½•
mv temp_papers/* food_research_data/papers/

# é‡å¯ç³»ç»Ÿ
python app.py
```

---

### ç¤ºä¾‹3: ä½¿ç”¨Webç•Œé¢

**è®¿é—®ï¼š** `http://localhost:5001/upload.html`

**ç•Œé¢æ“ä½œï¼š**
1. é€‰æ‹©"ç ”ç©¶è®ºæ–‡"
2. ç‚¹å‡»"é€‰æ‹©æ–‡ä»¶"
3. é€‰æ‹©å¤šä¸ªPDFï¼ˆCtrl/Cmd + ç‚¹å‡»ï¼‰
4. ç‚¹å‡»"ä¸Šä¼ "
5. ç­‰å¾…è¿›åº¦æ¡å®Œæˆ
6. ç³»ç»Ÿè‡ªåŠ¨é‡å»ºç´¢å¼•

---

## ğŸ§ª æµ‹è¯•å‘é‡åŒ–æ•ˆæœ

### åˆ›å»ºæµ‹è¯•è„šæœ¬

```python
#!/usr/bin/env python3
"""æµ‹è¯•PDFå‘é‡åŒ–"""

from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

# é…ç½®åµŒå…¥æ¨¡å‹
Settings.embed_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-small-zh-v1.5",
    cache_folder="./models"
)

# è¯»å–æ–‡æ¡£
print("ğŸ“„ è¯»å–æ–‡æ¡£...")
documents = SimpleDirectoryReader("food_research_data").load_data()

print(f"âœ… è¯»å–äº† {len(documents)} ä¸ªæ–‡æ¡£")
for doc in documents:
    print(f"  - {doc.metadata.get('file_name', 'æœªçŸ¥')}")
    print(f"    å†…å®¹é•¿åº¦: {len(doc.text)} å­—ç¬¦")
    print(f"    å‰100å­—: {doc.text[:100]}...")
    print()

# æ„å»ºç´¢å¼•
print("ğŸ”„ å‘é‡åŒ–ä¸­...")
index = VectorStoreIndex.from_documents(documents)
print("âœ… å‘é‡åŒ–å®Œæˆï¼")

# æµ‹è¯•æŸ¥è¯¢
query_engine = index.as_query_engine()
response = query_engine.query("è¿™äº›æ–‡çŒ®ä¸»è¦è®²ä»€ä¹ˆï¼Ÿ")
print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢ç»“æœ:\n{response}\n")
```

**è¿è¡Œæµ‹è¯•ï¼š**
```bash
python test_vectorization.py
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: PDFæ— æ³•è¯»å–æ€ä¹ˆåŠï¼Ÿ

**A: æ£€æŸ¥PDFç±»å‹**
```python
# æµ‹è¯•PDFæ˜¯å¦å¯è¯»
from llama_index.core import SimpleDirectoryReader

try:
    docs = SimpleDirectoryReader(
        input_files=["food_research_data/papers/your.pdf"]
    ).load_data()
    print(f"âœ… æˆåŠŸè¯»å–ï¼Œå†…å®¹é•¿åº¦: {len(docs[0].text)}")
except Exception as e:
    print(f"âŒ è¯»å–å¤±è´¥: {e}")
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# å®‰è£…å¢å¼ºPDFåº“
pip install pymupdf pdfminer.six

# æˆ–ä½¿ç”¨OCRï¼ˆæ‰«æç‰ˆPDFï¼‰
pip install pytesseract
```

---

### Q2: éœ€è¦é¢„å¤„ç†PDFå—ï¼Ÿ

**A: é€šå¸¸ä¸éœ€è¦ï¼**

LlamaIndexä¼šè‡ªåŠ¨ï¼š
- âœ… æå–æ–‡æœ¬
- âœ… æ¸…ç†æ ¼å¼
- âœ… åˆ†å—å¤„ç†
- âœ… å‘é‡åŒ–

**ä½†å¦‚æœPDFè´¨é‡å¾ˆå·®ï¼Œå¯ä»¥ï¼š**
```bash
# ä½¿ç”¨ä¸“ä¸šå·¥å…·é¢„å¤„ç†
pip install pdfplumber

# æˆ–åœ¨çº¿è½¬æ¢
# https://www.ilovepdf.com/
```

---

### Q3: æ‰«æç‰ˆPDFæ€ä¹ˆåŠï¼Ÿ

**A: éœ€è¦OCR**

```bash
# å®‰è£…OCRå·¥å…·
# macOS
brew install tesseract

# Ubuntu
sudo apt-get install tesseract-ocr

# Pythonåº“
pip install pytesseract pdf2image
```

**ä½¿ç”¨OCRï¼š**
```python
from llama_index.readers.file import PDFReader

pdf_reader = PDFReader(
    return_full_document=True,
    extract_images=True  # å¯ç”¨OCR
)
documents = pdf_reader.load_data(file="scanned.pdf")
```

---

### Q4: å‘é‡åŒ–éœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ

**æ—¶é—´ä¼°ç®—ï¼š**
- å°æ–‡æ¡£ï¼ˆ<10é¡µï¼‰ï¼š5-10ç§’
- ä¸­ç­‰æ–‡æ¡£ï¼ˆ10-50é¡µï¼‰ï¼š30-60ç§’
- å¤§æ–‡æ¡£ï¼ˆ>50é¡µï¼‰ï¼š2-5åˆ†é’Ÿ

**å½±å“å› ç´ ï¼š**
- æ–‡æ¡£å¤§å°
- CPUæ€§èƒ½
- æ˜¯å¦ä½¿ç”¨GPU

---

### Q5: å¦‚ä½•éªŒè¯å‘é‡åŒ–æˆåŠŸï¼Ÿ

**æ–¹æ³•1: æŸ¥çœ‹å­˜å‚¨ç›®å½•**
```bash
ls -lh storage/
# åº”è¯¥çœ‹åˆ°ï¼š
# - docstore.json
# - index_store.json
# - vector_store.json
```

**æ–¹æ³•2: æµ‹è¯•æŸ¥è¯¢**
```python
from persistent_storage import rag_system

# åˆå§‹åŒ–
rag_system.load_or_create_index()

# æŸ¥è¯¢
query_engine = rag_system.get_query_engine()
response = query_engine.query("æµ‹è¯•é—®é¢˜")
print(response)
```

**æ–¹æ³•3: æŸ¥çœ‹ç»Ÿè®¡**
```python
stats = rag_system.get_stats()
print(f"æ–‡æ¡£æ•°: {stats['total_documents']}")
```

---

## ğŸš€ å®Œæ•´å·¥ä½œæµç¨‹

### æ¨èæµç¨‹

```bash
# 1. å‡†å¤‡æ–‡çŒ®
# å°†æ‰€æœ‰PDFæ”¾åœ¨ä¸€ä¸ªæ–‡ä»¶å¤¹

# 2. æ‰¹é‡å¤åˆ¶
cp ~/Downloads/*.pdf food_research_data/papers/

# 3. æŸ¥çœ‹æ–‡ä»¶
ls food_research_data/papers/

# 4. å¯åŠ¨ç³»ç»Ÿï¼ˆè‡ªåŠ¨å‘é‡åŒ–ï¼‰
python app.py

# 5. ç­‰å¾…åˆå§‹åŒ–å®Œæˆ
# [åŠ è½½] è¯»å–äº† X ä¸ªæ–‡æ¡£
# [ä¿å­˜] ç´¢å¼•å·²ä¿å­˜

# 6. å¼€å§‹ä½¿ç”¨
# è®¿é—® http://localhost:5001
```

---

## ğŸ“Š å‘é‡åŒ–é…ç½®ä¼˜åŒ–

### è°ƒæ•´åˆ†å—å¤§å°

```python
# åœ¨ persistent_storage.py ä¸­
from llama_index.core import Settings

# å°æ–‡æ¡£ï¼šæ›´å°çš„chunk
Settings.chunk_size = 256
Settings.chunk_overlap = 20

# å¤§æ–‡æ¡£ï¼šæ›´å¤§çš„chunk
Settings.chunk_size = 1024
Settings.chunk_overlap = 100
```

### ä½¿ç”¨GPUåŠ é€Ÿ

```python
# å¦‚æœæœ‰NVIDIA GPU
Settings.embed_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-small-zh-v1.5",
    device="cuda"  # ä½¿ç”¨GPU
)
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. æ–‡ä»¶å‘½å
```bash
# å¥½çš„å‘½å
é£Ÿå“æ·»åŠ å‰‚_2024_å¼ ä¸‰.pdf
æŠ—æ°§åŒ–å‰‚ç ”ç©¶_Nature_2023.pdf

# é¿å…
paper1.pdf
æ–°å»ºæ–‡æ¡£.pdf
```

### 2. ç›®å½•ç»„ç»‡
```
food_research_data/
â”œâ”€â”€ papers/
â”‚   â”œâ”€â”€ é£Ÿå“å®‰å…¨/
â”‚   â”œâ”€â”€ è¥å…»å­¦/
â”‚   â””â”€â”€ æ·»åŠ å‰‚/
â””â”€â”€ datasets/
    â”œâ”€â”€ å®éªŒæ•°æ®/
    â””â”€â”€ è°ƒæŸ¥æ•°æ®/
```

### 3. å®šæœŸå¤‡ä»½
```bash
# å¤‡ä»½å‘é‡æ•°æ®åº“
cp -r storage/ storage_backup_$(date +%Y%m%d)/

# å¤‡ä»½åŸå§‹æ–‡æ¡£
tar -czf papers_backup.tar.gz food_research_data/
```

---

## ğŸ¯ æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. âœ… **ç›´æ¥ä¸Šä¼ PDF**ï¼Œä¸éœ€è¦è½¬Markdown
2. âœ… **è‡ªåŠ¨å‘é‡åŒ–**ï¼Œæ— éœ€æ‰‹åŠ¨æ“ä½œ
3. âœ… **æ”¯æŒå¤šç§æ ¼å¼**ï¼ŒPDF/Word/TXTéƒ½å¯ä»¥
4. âœ… **Webç•Œé¢ä¸Šä¼ **ï¼Œæœ€æ–¹ä¾¿
5. âœ… **æŒä¹…åŒ–å­˜å‚¨**ï¼Œé‡å¯ä¸ä¸¢å¤±

### å¿«é€Ÿå¼€å§‹

```bash
# 1. å¤åˆ¶PDF
cp your_paper.pdf food_research_data/papers/

# 2. å¯åŠ¨ç³»ç»Ÿ
python app.py

# 3. å¼€å§‹æé—®
# è®¿é—® http://localhost:5001
```

å°±è¿™ä¹ˆç®€å•ï¼ğŸš€
